# TransformerModelsBasic

This project provides a hands-on demonstration of various pre-trained transformer models using Hugging Face pipelines. The goal is to show how these models can be used without fine-tuning for different NLP tasks, such as:
âœ… Text classification
âœ… Named entity recognition (NER)
âœ… Question answering
âœ… Summarization
âœ… Translation
âœ… Text generation

Whatâ€™s Included?
ðŸ“Œ Code examples for multiple transformer models
ðŸ“Œ Sample inputs and corresponding outputs
ðŸ“Œ Step-by-step explanations of how to use Hugging Faceâ€™s pipeline()
ðŸ“Œ Comparison of different models for each taskTechnologies Used:
Hugging Face transformers
Python
Google Colab

Run the notebook in Google Colab or Jupyter Notebook to explore different transformer models in action.

 
